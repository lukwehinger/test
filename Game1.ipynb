{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: 129 53"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-d69eacceccc4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    211\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mcounter\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mactions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    212\u001b[0m             sess.run([W1, W2], feed_dict={current_game: play_mat[counter], input_label: actions[counter], reward_p: reward,\n\u001b[0;32m--> 213\u001b[0;31m                                          learning_rate_p:learning_rate})\n\u001b[0m",
      "\u001b[0;32m~/miniconda3/envs/myenv/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    776\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    777\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 778\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    779\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    780\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/myenv/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    980\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    981\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m--> 982\u001b[0;31m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[1;32m    983\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    984\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/myenv/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1030\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1031\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[0;32m-> 1032\u001b[0;31m                            target_list, options, run_metadata)\n\u001b[0m\u001b[1;32m   1033\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1034\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[0;32m~/miniconda3/envs/myenv/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1037\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1039\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1040\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/myenv/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1019\u001b[0m         return tf_session.TF_Run(session, options,\n\u001b[1;32m   1020\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1021\u001b[0;31m                                  status, run_metadata)\n\u001b[0m\u001b[1;32m   1022\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1023\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%matplotlib notebook\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "import time\n",
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "#params\n",
    "height = 50\n",
    "width = 60\n",
    "rollouts = 3000\n",
    "bar = 2\n",
    "bals = 1\n",
    "speed = 1\n",
    "verbose = True\n",
    "learning_rate = 0.01\n",
    "learning_rate_update = 0.999\n",
    "\n",
    "np.random.seed(0)\n",
    "DTYPE = tf.float32\n",
    "\n",
    "current_game = tf.placeholder(dtype=DTYPE,shape=(height, width),name='game')\n",
    "input_label = tf.placeholder(dtype=DTYPE, shape=(3), name='input_label')\n",
    "reward_p = tf.placeholder(dtype=DTYPE, name='reward')\n",
    "learning_rate_p = tf.placeholder(dtype=DTYPE, name='learning_rate')\n",
    "\n",
    "reshaped = tf.reshape(current_game, (1,height * width))\n",
    "W1 = tf.Variable(tf.random_normal([height * width, height * width], stddev=0.1), name=\"w1\", dtype=DTYPE)\n",
    "W2 = tf.Variable(tf.random_normal([height * width, 3], stddev=0.1), name=\"w2\", dtype=DTYPE)\n",
    "\n",
    "l1 = tf.nn.relu(tf.matmul(reshaped, W1))\n",
    "l2 = tf.matmul(l1, W2)\n",
    "p = tf.nn.softmax(tf.squeeze(l2))\n",
    "\n",
    "loss = tf.nn.softmax_cross_entropy_with_logits(labels=input_label, logits=p)\n",
    "grad = tf.gradients(loss, [W1, W2])\n",
    "\n",
    "W1 += learning_rate * -1 * reward_p * grad[0]\n",
    "W2 += learning_rate * -1 * reward_p * grad[1]\n",
    "\n",
    "sess = tf.InteractiveSession()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "def init(bals):\n",
    "    pos = []\n",
    "    for j in range(bals):\n",
    "        x_start = np.random.randint(round(height*0.25), round(height*0.75))\n",
    "        y_start = np.random.randint(round(width*0.25), round(width*0.75))\n",
    "        position = np.array([x_start, y_start])\n",
    "        speed = np.array([1 if np.random.randint(2) == 1 else -1, \n",
    "                 1 if np.random.randint(2) == 1 else -1])\n",
    "        pos.append([position, speed])\n",
    "\n",
    "    player1 = np.random.randint(height)\n",
    "    player2 = np.random.randint(height)\n",
    "    \n",
    "    return pos, player1, player2\n",
    "\n",
    "def update_ball(position, speed, a1, a2):\n",
    "    if position[0] <= 0:\n",
    "        speed[0] = np.abs(speed[0])\n",
    "    if position[0] >= height - 1:\n",
    "        speed[0] = -np.abs(speed[0])\n",
    "    if position[1] <= 0:\n",
    "        if speed[0] > 0 and a1 == 2:\n",
    "            speed[0] +=1\n",
    "        if speed[0] < 0 and a1 == 0:\n",
    "            speed[0] -=1\n",
    "        if speed[0] == 0 and a1 == 2:\n",
    "            speed[0] = 1\n",
    "        if speed[0] == 0 and a1 == 0:\n",
    "            apeed[0] = -1\n",
    "            \n",
    "        speed[1] = np.abs(speed[1])\n",
    "    if position[1] >= width - 1:\n",
    "        if speed[0] > 0 and a2 == 2:\n",
    "            speed[0] +=1\n",
    "        if speed[0] < 0 and a2 == 0:\n",
    "            speed[0] -=1\n",
    "        if speed[0] == 0 and a2 == 2:\n",
    "            speed[0] = 1\n",
    "        if speed[0] == 0 and a2 == 0:\n",
    "            apeed[0] = -1\n",
    "        \n",
    "        speed[1] = -np.abs(speed[1])\n",
    "    position+=speed\n",
    "    position[0] = position[0].clip(0, height-1)\n",
    "    position[1] = position[1].clip(0, width-1)\n",
    "    return [position, speed]\n",
    "    \n",
    "def update_player1(pos, player1):\n",
    "    return generic_player(pos, player1, 0)\n",
    "\n",
    "def update_player2(g):\n",
    "    probs = sess.run(p, feed_dict = {current_game : g})\n",
    "    return np.random.choice(np.arange(3), p=probs)\n",
    "    \n",
    "def get_matrix(g, pos, player1, player2):\n",
    "    g = g*0\n",
    "    for v in pos:\n",
    "        g[v[0][0], v[0][1]] = 2\n",
    "    g[player1 - bar: player1 + bar, 0] = 2\n",
    "    g[player2 - bar: player2 + bar, width -1] = 2\n",
    "    return g\n",
    "    \n",
    "def generic_player(pos, player, player_pos):\n",
    "    # First we check which ball we should pay attention to\n",
    "    dist = np.Inf\n",
    "    for v in pos:\n",
    "        if np.abs(player_pos - v[0][1]) < dist:\n",
    "            position = v[0]\n",
    "            dist = np.abs(player_pos - v[0][1])\n",
    "    if position[0] > player:\n",
    "        return 2\n",
    "    elif position[0] < player:\n",
    "        return 0\n",
    "    else:\n",
    "        return 1\n",
    "\n",
    "def update_player(player, action):\n",
    "    if action == 0:\n",
    "        player-=1\n",
    "    elif action == 2:\n",
    "        player+=1\n",
    "    if player < bar:\n",
    "        return bar\n",
    "    if player > height - bar - 1:\n",
    "        return height - bar - 1\n",
    "    return player\n",
    "    \n",
    "def check_game(pos, speed, player1, player2):\n",
    "    # Check player 1\n",
    "    for v in pos:\n",
    "        position = v[0]\n",
    "        if position[1] <= 0:\n",
    "            if position[0] > player1 + bar or position[0] < player1 - bar:\n",
    "                points[1] += 1\n",
    "                return 1\n",
    "    \n",
    "    # Check player 2:\n",
    "    for v in pos:\n",
    "        position = v[0]\n",
    "        if position[1] >= width - 1:\n",
    "            if position[0] > player2 + bar or position[0] < player2 - bar:\n",
    "                points[0] += 1\n",
    "                return -1\n",
    "\n",
    "    return 0\n",
    "\n",
    "plot = False\n",
    "\n",
    "# Play the game\n",
    "pos, player1, player2 = init(bals)\n",
    "g = np.zeros((height, width))\n",
    "a0_map = np.array([1,0,0])\n",
    "a1_map = np.array([0,1,0])\n",
    "a2_map = np.array([0,0,1])\n",
    "\n",
    "all_points = []\n",
    "\n",
    "if plot:\n",
    "    fig,ax = plt.subplots(1,1)\n",
    "points = np.zeros(2)\n",
    "\n",
    "for rollout in range(rollouts):\n",
    "    actions = []\n",
    "    play_mat = []\n",
    "    reward = 0\n",
    "    while True:\n",
    "        cg = check_game(pos, speed, player1, player2)\n",
    "        if cg != 0:\n",
    "            reward = cg\n",
    "            pos, player1, player2 = init(bals)\n",
    "            if verbose:\n",
    "                sys.stdout.write(\"\\r\" + \"Score: {} {}\".format(int(points[0]), int(points[1])))\n",
    "                sys.stdout.flush()\n",
    "            all_points.append(np.copy(points))\n",
    "            break\n",
    "\n",
    "        a1 = update_player1(pos, player1)\n",
    "        a2 = update_player2(g)\n",
    "        for v in pos:\n",
    "            v = update_ball(v[0], v[1], a1, a2)\n",
    "\n",
    "        if a2 ==0:\n",
    "            actions.append(a0_map)\n",
    "        elif a2 == 1:\n",
    "            actions.append(a1_map)\n",
    "        elif a2 == 2:\n",
    "            actions.append(a2_map)\n",
    "        \n",
    "        play_mat.append(g)\n",
    "        player1 = update_player(player1, a1)\n",
    "        player2 = update_player(player1, a2)\n",
    "        g = get_matrix(g, pos, player1, player2)\n",
    "\n",
    "        if plot:\n",
    "            ax.clear()\n",
    "            ax.imshow(g, cmap='Greys') \n",
    "            ax.set_title(\"Score: {} {}\".format(int(points[0]), int(points[1])))\n",
    "            fig.canvas.draw()\n",
    "    \n",
    "    if reward != 0:\n",
    "        learning_rate = learning_rate * learning_rate_update\n",
    "        if False:\n",
    "            sys.stdout.write(\"\\rUpdating the weights with reward {}\".format(reward))\n",
    "            sys.stdout.flush()\n",
    "        # We update the weights\n",
    "        for counter in range(len(actions)):\n",
    "            sess.run([W1, W2], feed_dict={current_game: play_mat[counter], input_label: actions[counter], reward_p: reward,\n",
    "                                         learning_rate_p:learning_rate})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pylab import *\n",
    "plot([x[0] for x in all_points])\n",
    "plot([x[1] for x in all_points])\n",
    "grid()\n",
    "legend(['generic player', 'learner'])\n",
    "title('Score')\n",
    "xlabel('Iterations')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
